# Example environment configuration for llama.vim
# Copy this file to .env and fill in your values

# LLM API endpoints
LLAMA_ENDPOINT_FIM="http://localhost:8081/infill"
LLAMA_ENDPOINT_INST="http://localhost:8081/v1/chat/completions"

# Model names
LLAMA_MODEL_INST="Devstral-Small-2-24B:Q4_K_M"
LLAMA_MODEL_FIM="Devstral-Small-2-24B:Q4_K_M"

# API authentication
LLAMA_API_KEY="sk-local"
